{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp: 1 Standard Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Perceptron:\n",
    "    def __init__(self, lrng_rate=0.01, epochs=100):\n",
    "        self.lrng_rate = lrng_rate\n",
    "        self.epochs = epochs\n",
    "        self.wts = None\n",
    "        self.b = None\n",
    "    def act_fun(self, linr_out):\n",
    "        return 1 if linr_out >= 0 else 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.wts = np.zeros(X.shape[1]) \n",
    "        self.b = 0  \n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                linr_out = np.dot(X[i], self.wts) + self.b\n",
    "                y_pred = self.act_fun(linr_out)\n",
    "                if y_pred != y[i]:\n",
    "                    update = self.lrng_rate * (y[i] - y_pred)\n",
    "                    self.wts += update * X[i] \n",
    "                    self.b += update \n",
    "\n",
    "    def predict(self, X):\n",
    "        linr_out = np.dot(X, self.wts) + self.b\n",
    "        return np.array([self.act_fun(x) for x in linr_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'Imputed_Csv_File.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "X = data.drop(columns=['label']).values\n",
    "y = data['label'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Fold accuracy , recall , f1, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary',zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    return accuracy, precision, recall, f1\n",
    "def cross_validate_model(model, X, y, folds=5):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "    return (np.mean(accuracies), np.mean(precisions), np.mean(recalls), np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67, Precision: 0.58, Recall: 0.68, F1 Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(lrng_rate=0.01, epochs=100)\n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(perceptron, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp:2 Sigmoid and binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6491\n",
      "Epoch 10, Loss: 0.5566\n",
      "Epoch 20, Loss: 0.5267\n",
      "Epoch 30, Loss: 0.5108\n",
      "Epoch 40, Loss: 0.5010\n",
      "Epoch 50, Loss: 0.4944\n",
      "Epoch 60, Loss: 0.4897\n",
      "Epoch 70, Loss: 0.4861\n",
      "Epoch 80, Loss: 0.4834\n",
      "Epoch 90, Loss: 0.4812\n",
      "Epoch 0, Loss: 0.6540\n",
      "Epoch 10, Loss: 0.5612\n",
      "Epoch 20, Loss: 0.5304\n",
      "Epoch 30, Loss: 0.5142\n",
      "Epoch 40, Loss: 0.5045\n",
      "Epoch 50, Loss: 0.4981\n",
      "Epoch 60, Loss: 0.4937\n",
      "Epoch 70, Loss: 0.4905\n",
      "Epoch 80, Loss: 0.4881\n",
      "Epoch 90, Loss: 0.4862\n",
      "Epoch 0, Loss: 0.6451\n",
      "Epoch 10, Loss: 0.5502\n",
      "Epoch 20, Loss: 0.5182\n",
      "Epoch 30, Loss: 0.5002\n",
      "Epoch 40, Loss: 0.4889\n",
      "Epoch 50, Loss: 0.4811\n",
      "Epoch 60, Loss: 0.4755\n",
      "Epoch 70, Loss: 0.4713\n",
      "Epoch 80, Loss: 0.4681\n",
      "Epoch 90, Loss: 0.4655\n",
      "Epoch 0, Loss: 0.6550\n",
      "Epoch 10, Loss: 0.5663\n",
      "Epoch 20, Loss: 0.5366\n",
      "Epoch 30, Loss: 0.5206\n",
      "Epoch 40, Loss: 0.5108\n",
      "Epoch 50, Loss: 0.5043\n",
      "Epoch 60, Loss: 0.4997\n",
      "Epoch 70, Loss: 0.4963\n",
      "Epoch 80, Loss: 0.4938\n",
      "Epoch 90, Loss: 0.4919\n",
      "Epoch 0, Loss: 0.6448\n",
      "Epoch 10, Loss: 0.5523\n",
      "Epoch 20, Loss: 0.5223\n",
      "Epoch 30, Loss: 0.5063\n",
      "Epoch 40, Loss: 0.4965\n",
      "Epoch 50, Loss: 0.4900\n",
      "Epoch 60, Loss: 0.4854\n",
      "Epoch 70, Loss: 0.4821\n",
      "Epoch 80, Loss: 0.4795\n",
      "Epoch 90, Loss: 0.4775\n",
      "Accuracy: 0.77, Precision: 0.73, Recall: 0.56, F1 Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PerceptronWithLoss:\n",
    "    def __init__(self, lrng_rate=0.01, epochs=100):\n",
    "        self.lrng_rate = lrng_rate\n",
    "        self.epochs = epochs\n",
    "        self.wts = None\n",
    "        self.b = None \n",
    "    def act_fun(self, linr_out):\n",
    "        return 1 / (1 + np.exp(-linr_out))\n",
    "    def act_drtv(self, out):\n",
    "        return out * (1 - out)\n",
    "    def bce(self, y_true, y_pred):\n",
    "        epsilon = 1e-15 \n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.wts = np.zeros(X.shape[1]) \n",
    "        self.b = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                linr_out = np.dot(X[i], self.wts) + self.b\n",
    "                y_pred = self.act_fun(linr_out)\n",
    "                err = y[i] - y_pred\n",
    "                self.wts += self.lrng_rate * err * self.act_drtv(y_pred) * X[i]\n",
    "                self.b += self.lrng_rate * err * self.act_drtv(y_pred)\n",
    "                epoch_loss += self.bce(y[i], y_pred)\n",
    "            epoch_loss /= X.shape[0]\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        linr_out = np.dot(X, self.wts) + self.b\n",
    "        y_pred = self.act_fun(linr_out)\n",
    "        return np.where(y_pred >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "perceptron = PerceptronWithLoss(lrng_rate=0.01, epochs=100)\n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(perceptron, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp4: Different Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74, Precision: 0.63, Recall: 0.63, F1 Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(scale_pos_weight=(len(y) - sum(y)) / sum(y)) \n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(model, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76, Precision: 0.70, Recall: 0.56, F1 Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(model, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76, Precision: 0.63, Recall: 0.72, F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(model, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74, Precision: 0.61, Recall: 0.73, F1 Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', class_weight='balanced')\n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(model, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exp3: Perceptron with Weighted Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PerceptronSigmoid:\n",
    "    def __init__(self, lrng_rate=0.01, epochs=80, class_weights=None):\n",
    "        self.lrng_rate = lrng_rate\n",
    "        self.epochs = epochs\n",
    "        self.wts = None\n",
    "        self.b = None\n",
    "        self.class_weights = class_weights\n",
    "    def act_fun(self, linr_out):\n",
    "        return 1 / (1 + np.exp(-linr_out))\n",
    "    def act_drtv(self, out):\n",
    "        return out * (1 - out)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.wts = np.zeros(X.shape[1])\n",
    "        self.b = 0\n",
    "        if self.class_weights is None:\n",
    "            unique_classes, counts = np.unique(y, return_counts=True)\n",
    "            total_samples = len(y)\n",
    "            self.class_weights = {cls: total_samples / count for cls, count in zip(unique_classes, counts)}\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                linr_out = np.dot(X[i], self.wts) + self.b\n",
    "                y_pred = self.act_fun(linr_out)\n",
    "                err = y[i] - y_pred\n",
    "                sample_weight = self.class_weights[y[i]]\n",
    "                self.wts += self.lrng_rate * sample_weight * err * self.act_drtv(y_pred) * X[i]\n",
    "                self.b += self.lrng_rate * sample_weight * err * self.act_drtv(y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        linr_out = np.dot(X, self.wts) + self.b\n",
    "        y_pred = self.act_fun(linr_out)\n",
    "        return np.where(y_pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76, Precision: 0.66, Recall: 0.66, F1 Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0: 1, 1: 1.5}\n",
    "model =  PerceptronSigmoid(lrng_rate=0.01, epochs=100, class_weights=class_weights) \n",
    "accuracy_cv, precision_cv, recall_cv, f1_cv = cross_validate_model(model, X, y)\n",
    "print(f\"Accuracy: {accuracy_cv:.2f}, Precision: {precision_cv:.2f}, Recall: {recall_cv:.2f}, F1 Score: {f1_cv:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
